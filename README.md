# NeuroEmployee-RAG-Chatbot
This repository contains the NeuroEmployee service, an example of a RAG (Retrieval-Augmented Generation) application designed to answer questions based on a loaded document database.

What the Project Does:

Loads documents from the docs/ folder (or uses demo texts).
Builds a FAISS vector index using SentenceTransformer embeddings.
Finds relevant context for user queries and generates responses using a selected LLM.
Implements filtering of queries to detect confidential data.
Checks generated responses for hallucinations (by comparing embeddings) and length.
Collects query metrics and latency data through Prometheus.

Main Purpose:

Demonstrates a production approach to a RAG bot with security and monitoring.
Allows for the selection of different LLM models and embeddings through aliases.

Security:

Blocks queries containing personal or financial data (such as passwords, passport details, or SNILS) to prevent leaks.
Hallucinations: Filters out responses whose vector similarity to the context is below 0.5 or whose length is fewer than 10 words.

Safety:

Ensures the bot does not become an unofficial "storage" of personal information.
The hallucination detector makes the RAG system more reliable: it either responds with factual information from the database or honestly admits it doesn't know.

==================================================================================================================================================================================================================

–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–µ—Ä–≤–∏—Å NeuroEmployee ‚Äî –ø—Ä–∏–º–µ—Ä RAG-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (Retrieval-Augmented Generation) –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –±–∞–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ß—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–µ–∫—Ç:

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –ø–∞–ø–∫–∏ docs/ (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–µ–º–æ-—Ç–µ–∫—Å—Ç—ã).
–°—Ç—Ä–æ–∏—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π FAISS-–∏–Ω–¥–µ–∫—Å –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö SentenceTransformer.
–ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é –≤—ã–±—Ä–∞–Ω–Ω–æ–π LLM.
–†–µ–∞–ª–∏–∑—É–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤) –∏ –¥–ª–∏–Ω—É.
–°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∑–∞–¥–µ—Ä–∂–∫–∏ —á–µ—Ä–µ–∑ Prometheus.
–û—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ:

–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–∞–∫—à–Ω-–ø–æ–¥—Ö–æ–¥–∞ –∫ RAG-–±–æ—Ç—É —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º.
–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π LLM –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ –∞–ª–∏–∞—Å—ã.
–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:

–ë–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã —Å –ª–∏—á–Ω—ã–º–∏ –∏–ª–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–ø–∞—Ä–æ–ª–∏, –ø–∞—Å–ø–æ—Ä—Ç, –°–ù–ò–õ–°), —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å —É—Ç–µ—á–∫–∏.
–ì–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏: –æ—Ç—Å–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç—ã, –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å –∫–æ—Ç–æ—Ä—ã—Ö –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –Ω–∏–∂–µ 0.5 –∏–ª–∏ –¥–ª–∏–Ω–∞ –º–µ–Ω—å—à–µ 10 —Å–ª–æ–≤.
–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –±–æ—Ç –Ω–µ —Å—Ç–∞–Ω–µ—Ç –≤–Ω–µ—à—Ç–∞—Ç–Ω—ã–º ¬´—Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º¬ª –ø–µ—Ä—Å–æ–Ω–∞–ª–∫–∏.
–î–µ—Ç–µ–∫—Ç–æ—Ä –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –¥–µ–ª–∞–µ—Ç RAG-—Å–∏—Å—Ç–µ–º—É –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω–æ–π: –æ–Ω–∞ –ª–∏–±–æ –æ—Ç–≤–µ—Ç–∏—Ç –ø–æ —Ñ–∞–∫—Ç—É –∏–∑ –±–∞–∑—ã, –ª–∏–±–æ —á–µ—Å—Ç–Ω–æ –ø—Ä–∏–∑–Ω–∞–µ—Ç, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—Ç.


=====================================================================================================================================================================================================================



# üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
!pip install \
    torch torchvision \
    transformers>=4.41.0 \
    llama-index==0.12.35 \
    sentence-transformers>=2.2.2 \
    faiss-cpu \
    optuna==4.3.0 \
    mlflow==2.21.0 \
    prometheus-client \
    tensorflow-cpu==2.19.0



# üì¶ –ò–º–ø–æ—Ä—Ç—ã
import logging
import os
import re
import sys
import argparse
import numpy as np
import time
from collections import Counter

# ML-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏
import torch
import tensorflow as tf

# Hugging Face
from transformers import AutoTokenizer, AutoModelForCausalLM

# RAG-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document

# –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –ø–æ–∏—Å–∫
from sentence_transformers import SentenceTransformer
import faiss
from sklearn.metrics.pairwise import cosine_similarity

# –ú–µ—Ç—Ä–∏–∫–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
from prometheus_client import CollectorRegistry, Counter as PromCounter, Histogram, start_http_server


# üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
)
logger = logging.getLogger(__name__)


# üéõÔ∏è –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
# –°–ª–æ–≤–∞—Ä–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–∞–ª–∏–∞—Å—ã ‚Üí HF –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä)
AVAILABLE_LLM = {
    "tiny": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "gpt2": "gpt2",
    "opt-125m": "facebook/opt-125m"
}
AVAILABLE_EMBED = {
    "minilm": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "all-mpnet": "sentence-transformers/all-mpnet-base-v2"
}


# üß† –ö–ª–∞—Å—Å NeuroEmployee
# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ RAG-–±–æ—Ç–∞
class NeuroEmployee:
    def __init__(self, docs_dir: str, llm_alias: str, embed_alias: str, allowed_roles: list = ["analyst"]):
        # 1) –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        # –ï—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –µ—Å—Ç—å ‚Äî —á–∏—Ç–∞–µ–º, –∏–Ω–∞—á–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä
        if os.path.isdir(docs_dir):
            self.docs = SimpleDirectoryReader(input_dir=docs_dir).load_data()
        else:
            logger.warning(f"Directory '{docs_dir}' not found, loading sample documents.")
            sample_texts = [
                # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è RAG-–∫–æ–Ω–≤–µ–π–µ—Ä–∞
                "–¢–ó –ø–æ –ì–û–°–¢ 34.602-2020 –¥–æ–ª–∂–Ω–æ –≤–∫–ª—é—á–∞—Ç—å: –æ–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è, –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ—É–Ω–∫—Ü–∏—è–º, —ç—Ç–∞–ø—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.",
                "–î–ª—è —Å–º–µ–Ω—ã –≤–∏–¥–∞ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –ï–ì–†–ò–ü –Ω—É–∂–Ω–æ –ø–æ–¥–∞—Ç—å –∑–∞—è–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø–æ—Ä—Ç–∞–ª –∏ –ø—Ä–∏–ª–æ–∂–∏—Ç—å –Ω–æ–≤—ã–µ –û–ö–í–≠–î.",
                "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ—Å–º–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª—ë—Ç–∞—Ö –Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –†–æ—Å–∫–æ—Å–º–æ—Å.",
                "–î–ª—è —Å–º–µ–Ω—ã –Ω–æ–º–µ—Ä–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤ mos.ru –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ –°–ú–°."
            ]
            self.docs = [Document(text=t) for t in sample_texts]

        # 2) –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        if embed_alias not in AVAILABLE_EMBED:
            raise ValueError(f"Embed model '{embed_alias}' not supported. Available: {list(AVAILABLE_EMBED.keys())}")
        self.embed_model = SentenceTransformer(AVAILABLE_EMBED[embed_alias])

        # 3) FAISS-–∏–Ω–¥–µ–∫—Å
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä—ã –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
        embeddings = [self.embed_model.encode(doc.text) for doc in self.docs]
        dim = embeddings[0].shape[0]
        self.index = faiss.IndexFlatL2(dim)
        self.index.add(np.array(embeddings))

        # 4) –ó–∞–≥—Ä—É–∑–∫–∞ LLM (—Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä + –º–æ–¥–µ–ª—å)
        if llm_alias not in AVAILABLE_LLM:
            raise ValueError(f"LLM '{llm_alias}' not supported. Available: {list(AVAILABLE_LLM.keys())}")
        self.tokenizer = AutoTokenizer.from_pretrained(AVAILABLE_LLM[llm_alias])
        self.model = AutoModelForCausalLM.from_pretrained(AVAILABLE_LLM[llm_alias])
        self.model.eval() # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM

        # 5) –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ACL (—Å–ø–∏—Å–æ–∫ —Ä–æ–ª–µ–π —Å –¥–æ—Å—Ç—É–ø–æ–º)
        self.allowed_roles = allowed_roles

        # 6) –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
        # –ë–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã —Å –ø–∞—Ä–æ–ª—è–º–∏, –ø–∞—Å–ø–æ—Ä—Ç–∞–º–∏, –°–ù–ò–õ–° –∏ —Ç.–ø.
        self.sensitive_pattern = re.compile(r"(–ø–∞—Ä–æ–ª[—å—è]|–∫—Ä–µ–¥–∏—Ç–Ω–∞—è –∫–∞—Ä—Ç–∞|–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω[—ã—ã—Ö] –¥–∞–Ω–Ω—ã–µ|–ø–∞—Å–ø–æ—Ä—Ç|–°–ù–ò–õ–°|–ò–ù–ù)", re.IGNORECASE)

        # 7) –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç—Ä–∏–∫ Prometheus
        self.registry = CollectorRegistry()
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä—ã (–Ω–∞ —Å–ª—É—á–∞–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞)
        for collector in list(self.registry._collector_to_names):
            self.registry.unregister(collector)
        self.request_counter = PromCounter('neuro_employee_requests_total', '–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤', registry=self.registry)
        self.latency_hist = Histogram('neuro_employee_latency_seconds', '–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞', registry=self.registry)
        # –ó–∞–ø—É—Å–∫–∞–µ–º HTTP-—Å–µ—Ä–≤–µ—Ä –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫ –Ω–∞ –ø–æ—Ä—Ç—É 8001
        start_http_server(8001, registry=self.registry)

    def check_access(self, user_id):
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        return "analyst" in self.allowed_roles

    def validate_answer(self, context, answer):
        # –ü—Ä–æ—Å—Ç–æ–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –æ—Ç–≤–µ—Ç–∞
        ctx_emb = self.embed_model.encode(context)
        ans_emb = self.embed_model.encode(answer)
        sim = cosine_similarity([ctx_emb], [ans_emb])[0][0]
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å –∏–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ‚Äî —Å—á–∏—Ç–∞–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–µ–π
        return sim > 0.50

    def answer(self, user_id, query):
        self.request_counter.inc()
        start = time.time()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º ACL
        if not self.check_access(user_id):
            return "–£ –≤–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        if self.sensitive_pattern.search(query):
            return "–ó–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."

        # –ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        try:
            q_emb = self.embed_model.encode(query)
            dists, idx = self.index.search(np.array([q_emb]), k=3)
            context = self.docs[idx[0][0]].text
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return "–ù–µ –º–æ–≥—É –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        prompt = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n–í–æ–ø—Ä–æ—Å: {query}"
        input_ids = self.tokenizer(prompt, return_tensors="pt").input_ids
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        out = self.model.generate(
            input_ids,
            max_new_tokens=200,
            do_sample=True,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            top_k=70,
            top_p=0.95,
            temperature=0.7
        )
        answer = self.tokenizer.decode(out[0], skip_special_tokens=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –∏ –¥–ª–∏–Ω—É
        if not self.validate_answer(context, answer) or len(answer.split()) < 10:
            return "–ù–µ –º–æ–≥—É –¥–∞—Ç—å —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É."

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞
        self.latency_hist.observe(time.time() - start)
        return answer


# üìä –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ –Ω–∞–ø—Ä—è–º—É—é
if __name__ == "__main__":
    # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã Colab/IPython (-f <kernel>)
    if any(arg.startswith('-f') for arg in sys.argv[1:]):
        sys.argv = sys.argv[:1]

    # –†–∞–∑–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(description="NeuroEmployee with selectable models")
    parser.add_argument("--docs_dir", type=str, default="docs/", help="–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
    parser.add_argument("--llm", type=str, choices=list(AVAILABLE_LLM.keys()), default="tiny", help="–í—ã–±–æ—Ä LLM –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö")
    parser.add_argument("--embed", type=str, choices=list(AVAILABLE_EMBED.keys()), default="minilm", help="–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    parser.add_argument("--roles", nargs='+', default=["analyst"], help="–°–ø–∏—Å–æ–∫ —Ä–æ–ª–µ–π —Å –¥–æ—Å—Ç—É–ø–æ–º")
    args, _ = parser.parse_known_args()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ—Ç–∞
    neuro = NeuroEmployee(
        docs_dir=args.docs_dir,
        llm_alias=args.llm,
        embed_alias=args.embed,
        allowed_roles=args.roles
    )

    # –î–µ–º–æ–∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    tests = [
        ("user1", "–ö–∞–∫ –æ—Ñ–æ—Ä–º–∏—Ç—å –¢–ó –ø–æ –ì–û–°–¢?"),
        ("user2", "–ú–æ–π –ø–∞—Ä–æ–ª—å 123"),
        ("user3", "–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–º–µ–Ω–µ –û–ö–í–≠–î"),
        ("user4", "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–µ—Ä–º–∏–Ω?")
    ]

    for uid, q in tests:
        print(f"--- {q} ---")
        print(neuro.answer(uid, q))
